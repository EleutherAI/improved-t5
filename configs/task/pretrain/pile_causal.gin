from __gin__ import dynamic_registration

import __main__ as train_script
import seqio
from t5x import utils
from t5x import models
from t5x import partitioning

import data.pile.tasks

include 't5x/configs/runs/pretrain.gin'

BATCH_SIZE = 2048
DROPOUT_RATE = 0.0
MIXTURE_OR_TASK_NAME = "pile_causal_lm"
TASK_FEATURE_LENGTHS = {"inputs": 1, "targets": 512}

train_script.train:
  run_eval_before_training = True
  eval_steps = 100
  eval_period = %SAVING_PERIOD
  infer_eval_dataset_cfg = @infer_eval/utils.DatasetConfig()
  inference_evaluator_cls = @seqio.Evaluator

infer_eval/utils.DatasetConfig:
  mixture_or_task_name = %MIXTURE_OR_TASK_NAME
  task_feature_lengths = %TASK_FEATURE_LENGTHS
  split = 'validation'
  batch_size = 64
  seed = 0
  shuffle = False

seqio.Evaluator:
  logger_cls = [@seqio.PyLoggingLogger, @seqio.TensorBoardLogger, @seqio.JSONLogger]
  num_examples = 2048 # None  # Use all examples in the infer_eval dataset.

utils.SaveCheckpointConfig:
  keep = None
  period = %SAVING_PERIOD
